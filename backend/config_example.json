{
    "auto_start_runners": true,
    "api": {
        "host": "0.0.0.0",
        "port": 8080,
        "health_endpoint": "/health"
    },
    "retry_config": {
        "max_retries": 3,
        "base_delay_seconds": 2,
        "max_delay_seconds": 30,
        "retry_on_model_loading": true
    },
    "runner1": {
        "type": "llama-server",
        "path": "/path/to/llama-server",
        "host": "127.0.0.1",
        "port": 8085,
        "inherit_env": true,
        "env": {
            "MY_VAR": "1",
            "RUNNER_SPECIFIC_VAR": "value"
        },
        "extra_args": ["--verbose"]
    },
    "runner2": {
        "type": "llama-server",
        "path": "/path/to/llama-server",
        "host": "127.0.0.1",
        "port": 8086,
        "inherit_env": true,
        "env": {},
        "extra_args": []
    },
    "models": [
        {
            "runner": "runner1",
            "model": "/path/to/model1.gguf",
            "model_alias": "model1",
            "n_ctx": 4096,
            "n_batch": 512,
            "n_threads": 4,
            "offload_kqv": true,
            "flash_attn": "on",
            "use_mlock": true,
            "main_gpu": 0,
            "tensor_split": [1.0, 0.0],
            "n_gpu_layers": 99,
            "jinja": true,
            "env": {
                "GGML_VULKAN_DEVICE": "0",
                "MODEL_SPECIFIC_VAR": "example"
            },
            "args": ""
        },
        {
            "runner": "runner2",
            "model": "/path/to/model2.gguf",
            "model_alias": "model2",
            "n_ctx": 8192,
            "n_batch": 256,
            "n_threads": 8,
            "chat_template": "mistral-instruct",
            "offload_kqv": false,
            "flash_attn": "off",
            "use_mlock": true,
            "main_gpu": 0,
            "tensor_split": [1.0, 0.0],
            "n_gpu_layers": 50,
            "jinja": true,
            "split_mode": "row",
            "cache-type-k": "q8_0",
            "cache-type-v": "q8_0",
            "args": "--some-custom-arg --another-arg value"
        },
        {
            "runner": "runner2",
            "model": "/path/to/model3.gguf",
            "model_alias": "model3",
            "args": "--ctx-size 8000 --batch-size 512 --threads 8 --flash-attn on --mlock --device Vulkan1"
        },
        {
            "runner": "runner1",
            "model": "/path/to/vision_model.gguf",
            "mmproj": "/path/to/mmproj.gguf",
            "model_alias": "vision_model",
            "n_ctx": 32768,
            "n_batch": 256,
            "n_threads": 8,
            "chat_template": "gemma",
            "offload_kqv": true,
            "flash_attn": "auto",
            "use_mlock": true,
            "tensor_split": [1.0, 0.0],
            "n_gpu_layers": 99,
            "rope-scaling": "linear",
            "rope-scale": 2,
            "yarn-orig-ctx": 32768,
            "args": ""
        },
        {
            "runner": "runner2",
            "model": "/path/to/reranker_model.gguf",
            "model_alias": "reranker_model",
            "n_ctx": 8192,
            "n_batch": 512,
            "n_threads": 8,
            "offload_kqv": true,
            "flash_attn": "on",
            "use_mlock": true,
            "reranking": true,
            "tensor_split": [1.0, 0.0],
            "n_gpu_layers": 99,
            "args": ""
        },
        {
            "runner": "runner1",
            "model": "/path/to/embedding_model.gguf",
            "model_alias": "embedding_model",
            "n_ctx": 8192,
            "n_batch": 512,
            "n_threads": 8,
            "offload_kqv": true,
            "flash_attn": "on",
            "use_mlock": true,
            "embedding": true,
            "pooling": "cls",
            "tensor_split": [1.0, 0.0],
            "n_gpu_layers": 99,
            "args": ""
        }
    ]
}
