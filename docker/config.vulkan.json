{
    "auto_start_runners": true,
    "api": {
        "host": "0.0.0.0",
        "port": 8090,
        "health_endpoint": "/health"
    },
    "retry_config": {
        "max_retries": 3,
        "base_delay_seconds": 2,
        "max_delay_seconds": 30,
        "retry_on_model_loading": true
    },
    "runner_vulkan": {
        "type": "llama-server",
        "path": "/usr/local/bin/llama-server",
        "host": "127.0.0.1",
        "port": 8095,
        "inherit_env": true,
        "env": {},
        "auto_unload_timeout_seconds": 300,
        "extra_args": ["--verbose"]
    },
    "models": [
        {
            "runner": "runner_vulkan",
            "model": "/app/models/your-model.gguf",
            "model_alias": "vulkan-model",
            "n_ctx": 4096,
            "n_batch": 512,
            "n_threads": 4,
            "offload_kqv": true,
            "flash_attn": "on",
            "use_mlock": true,
            "n_gpu_layers": 99,
            "jinja": true,
            "args": "--device Vulkan0"
        }
    ]
}

